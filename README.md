<div align="center">

<!-- logo -->

### ì‚¬ì§„ ì† ì¥ì†Œì™€ inputí•œ ë„ì‹œì™€ì˜ ìœ ì‚¬ë„ âœ…

[<img src="https://img.shields.io/badge/-readme.md-important?style=flat&logo=google-chrome&logoColor=white" />]() [<img src="https://img.shields.io/badge/-tech blog-blue?style=flat&logo=google-chrome&logoColor=white" />]() [<img src="https://img.shields.io/badge/release-v0.0.0-yellow?style=flat&logo=google-chrome&logoColor=white" />]() 
<br/> [<img src="https://img.shields.io/badge/í”„ë¡œì íŠ¸ ê¸°ê°„-2024.10.25~2024.10.27-green?style=flat&logo=&logoColor=white" />]()

</div> 

## ğŸ“ ì†Œê°œ


1. **ì–´ë–¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‹¶ì€ì§€ ì •ì˜**
    
        ê°€ì§€ê³  ìˆëŠ” ì´ë¯¸ì§€ê°€ ì…ë ¥í•œ ì§€ì—­ê³¼ ìœ ì‚¬í•œì§€ ì•Œê¸°
    
2. **ë¬¸ì œë¥¼ í•´ê²° í•  ìˆ˜ ìˆëŠ” ai task ì •ë¦¬**
    - ì´ë¯¸ì§€ì˜ urlë¥¼ ë„£ê³ , í•´ë‹¹ ì´ë¯¸ì§€ê°€ ì–´ëŠ ì§€ì—­ì¸ì§€(choices) í…ìŠ¤íŠ¸ ì…ë ¥í•´ë³´ê¸°(ìƒëµì‹œ ì •í™•ë„ê°€ ë–¨ì–´ì§),
    ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì…ë ¥ëœ ì§€ì—­ë“¤ì˜ ìœ ì‚¬ë„ë¥¼ ë¹„êµ í›„ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ê°’ì´ ì¶œë ¥
    - í•œêµ­ì–´ë¡œ ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë³€í™˜í•˜ì—¬ ì°¾ì•„ì£¼ê³ , ê²°ê³¼ê°’ì„ ì…ë ¥í•œ ë‹¨ì–´(í•œêµ­ì–´)ë¡œ ì¶œë ¥
3. **task ë³„ ëª¨ë¸ë“¤ì„ ê°€ì ¸ì™€ ì í•©í•œ ëª¨ë¸ ì°¾ê¸°**
    
    geolocal/StreetCLIP
    
    google-t5/t5-base
    
    - ì½”ë“œ
        
        ```jsx
        from PIL import Image
        import requests
        import torch
        from transformers import CLIPProcessor, CLIPModel
        from googletrans import Translator
        
        model = CLIPModel.from_pretrained("geolocal/StreetCLIP")
        processor = CLIPProcessor.from_pretrained("geolocal/StreetCLIP")
        
        # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
        url = "https://huggingface.co/geolocal/StreetCLIP/resolve/main/sanfrancisco.jpeg"
        image = Image.open(requests.get(url, stream=True).raw)
        
        # ì§€ì—­ ì´ë¦„ ì…ë ¥ë°›ê¸°
        choices = []
        original_choices = []  # ì›ë˜ ì…ë ¥í•œ ì§€ì—­ ì´ë¦„ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸(í•œêµ­ì–´)
        translator = Translator()  # ë²ˆì—­ê¸° ì´ˆê¸°í™”
        
        while True:
            print("ì§€ì—­ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”. ì…ë ¥ì„ ëë‚´ë ¤ë©´ 'x'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            
            while True:
                location = input("ì§€ì—­ ì´ë¦„: ")
                if location.lower() == "x":
                    break
                if location:  
                    translated_location = translator.translate(location, src='ko', dest='en').text
                    choices.append(translated_location)  # ë²ˆì—­ëœ ì§€ì—­ ì´ë¦„ ì¶”ê°€(ì˜ì–´)
                    original_choices.append(location)  # ì›ë˜ ì§€ì—­ ì´ë¦„ ì¶”ê°€(í•œêµ­ì–´)
        
            if not choices:
                print("ì…ë ¥ëœ ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤. ì •í™•í•œ ì¶”ë¡ ì„ ìœ„í•´ í•œ ê°€ì§€ ì´ìƒì˜ ì§€ì—­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                break
        
        # ì´ë¯¸ì§€ì™€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì— ì „ë‹¬
        inputs = processor(text=choices, images=image, return_tensors="pt", padding=True)
        
        outputs = model(**inputs)
        logits_per_image = outputs.logits_per_image
        probs = logits_per_image.softmax(dim=1)
        
        # ìœ ì‚¬ë„ê°€ ê°€ì¥ í° ê°’ì˜ ì¸ë±ìŠ¤ êµ¬í•˜ê³ , ìœ ì‚¬ë„ ê°’ êµ¬í•˜ê¸°
        max_index = torch.argmax(logits_per_image).item()
        most_similar_location = original_choices[max_index]  # ì›ë˜ ì§€ì—­ ì´ë¦„(í•œêµ­ì–´) ì‚¬ìš©
        similarity = probs[0, max_index].item() * 100  # ìœ ì‚¬ë„ ê°’ì„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
        
        if similarity < 70:
            print(f"ì…ë ¥í•˜ì‹  ì§€ì—­ë“¤ì€ ì´ë¯¸ì§€ì™€ ìœ ì‚¬ë„ê°€ ë‚®ì•„ ì •í™•í•˜ê²Œ ì°¾ì•„ì¤„ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤.\n ê·¸ëŸ¬ë‚˜ ì´ ì´ë¯¸ì§€ëŠ” í˜„ì¬ ì…ë ¥í•˜ì‹  ì§€ì—­ ì¤‘ {most_similar_location}ê°€ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ìœ ì‚¬ë„ëŠ” {similarity:.2f}%ì…ë‹ˆë‹¤.")
        else:
            print(f"ì´ ì´ë¯¸ì§€ëŠ” {most_similar_location}ê°€ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ìœ ì‚¬ë„ëŠ” {similarity:.2f}%ì…ë‹ˆë‹¤.")
        
        ```
        
4. **ëª¨ë¸ì„ ì´ìš©í•œ fast api ì„œë¹™**
    - API ì½”ë“œ
        
        ```jsx
        from fastapi import FastAPI, HTTPException
        from fastapi.middleware.cors import CORSMiddleware
        from pydantic import BaseModel
        from PIL import Image
        import requests
        import torch
        from transformers import CLIPProcessor, CLIPModel
        from googletrans import Translator
        from io import BytesIO
        
        app = FastAPI()
        
        app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],  
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
        
        model = CLIPModel.from_pretrained("geolocal/StreetCLIP")
        processor = CLIPProcessor.from_pretrained("geolocal/StreetCLIP")
        translator = Translator() 
        
        class LocationRequest(BaseModel):
            image_url: str
            locations: list[str]
        
        @app.post("/analyze/")
        async def analyze_location(request: LocationRequest):
            try:
                image = Image.open(requests.get(request.image_url, stream=True).raw)
            except Exception as e:
                raise HTTPException(status_code=400, detail="URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
            # ì§€ì—­ ì´ë¦„ ì…ë ¥ë°›ê¸°
            choices = []
            original_choices = []  
        
            for location in request.locations:
                if location:  
                    translated_location = translator.translate(location, src='ko', dest='en').text
                    choices.append(translated_location)  # ë²ˆì—­ëœ ì§€ì—­ ì´ë¦„ ì¶”ê°€
                    original_choices.append(location)  # ì›ë˜ ì§€ì—­ ì´ë¦„ ì¶”ê°€
        
            # ì˜ˆì™¸ì²˜ë¦¬
            if not choices:
                raise HTTPException(status_code=400, detail="ì§€ì—­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
            # ì´ë¯¸ì§€ì™€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì— ì „ë‹¬
            inputs = processor(text=choices, images=image, return_tensors="pt", padding=True)
        
            outputs = model(**inputs)
            logits_per_image = outputs.logits_per_image
            probs = logits_per_image.softmax(dim=1)
        
            # ê°€ì¥ ìœ ì‚¬ë„ê°€ í° ê°’ì˜ ì¸ë±ìŠ¤ êµ¬í•˜ê¸°
            max_index = torch.argmax(logits_per_image).item()
        
            # ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ì§€ì—­ê³¼ ìœ ì‚¬ë„ ê°’
            most_similar_location = original_choices[max_index]  
            similarity = probs[0, max_index].item() * 100  # ìœ ì‚¬ë„ ê°’ì„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
        
            if similarity <= 75:
                return {
                    "message": (
                        f"ì…ë ¥í•˜ì‹  ì§€ì—­ë“¤ì€ ì´ë¯¸ì§€ì™€ ìœ ì‚¬ë„ê°€ ë‚®ì•„ ì •í™•í•˜ê²Œ ì°¾ì•„ì¤„ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤."
                        f"\nê·¸ëŸ¬ë‚˜ ì´ ì´ë¯¸ì§€ëŠ” í˜„ì¬ ì…ë ¥í•˜ì‹  ì§€ì—­ ì¤‘ {most_similar_location}ê°€ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ìŠµë‹ˆë‹¤."
                        f" ìœ ì‚¬ë„ëŠ” {similarity:.2f}%ì…ë‹ˆë‹¤."
                    )
                }
            else:
                return {
                    "message": f"ì´ ì´ë¯¸ì§€ëŠ” {most_similar_location}ê°€ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ìœ ì‚¬ë„ëŠ” {similarity:.2f}%ì…ë‹ˆë‹¤."
                }
        
        if __name__ == "__main__":
            import uvicorn
            uvicorn.run(app, host="0.0.0.0", port=8000)
        
        ```
        

- ê²°ê³¼ ì´ë¯¸ì§€
    
    ë†’ì€ ìœ ì‚¬ë„(75% ì´ˆê³¼)ê°€ ë‚˜ì˜¨ ê²°ê³¼
    
    <img align="center" alt="ê²°ê³¼" src="../Img/ë¦¬í€˜ìŠ¤íŠ¸ë°”ë””.PNG" width="240px" />
    
    <img align="center" alt="ê²°ê³¼" src="../Img/ê²°ê³¼1.PNG" width="240px" />
    
    ë‚®ì€ ìœ ì‚¬ë„(75% ì´í•˜)ê°€ ë‚˜ì˜¨ ê²°ê³¼
    <img align="center" alt="ê²°ê³¼" src="../Img/ê²°ê³¼2.PNG" width="240px" />

    
- ì˜ˆì™¸ì²˜ë¦¬
    
    ì§€ì—­ ì…ë ¥ì´ ì•ˆëœ ì˜ˆ)
    
   <img align="center" alt="ê²°ê³¼" src="../Img/ì§€ì—­ ì…ë ¥ì•ˆí•œ ì—ëŸ¬.PNG" width="240px" />
    
    ì´ë¯¸ì§€ URLì´ ì…ë ¥ ì•ˆëœ ì˜ˆ)
    
   <img align="center" alt="ê²°ê³¼" src="../Img/URLì—ëŸ¬.PNG" width="240px" />
    

ìµœì¢… ì™„ì„±

- ìµœì¢… ì™„ì„± html ì´ë¯¸ì§€
    
   <img align="center" alt="ê²°ê³¼" src="../Img/cssë„£ê¸°.PNG" width="240px" />

<br />

